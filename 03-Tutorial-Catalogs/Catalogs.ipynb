{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80870775",
   "metadata": {},
   "source": [
    "# Catalogs\n",
    "\n",
    "**Objective:** Learn about how Pegasus uses catalogs to map an abstract workflow to an executable workflow.\n",
    "\n",
    "The Abstract Workflow description that you specify to Pegasus is portable, and usually does not contain any locations to physical input files, executables or cluster end points where jobs are executed. Pegasus uses three information catalogs during the planning process.\n",
    "\n",
    "<img src=\"images/catalogs.png\"/>\n",
    "\n",
    "The Pegasus documentation provides more details about catalogs [here](https://pegasus.isi.edu/documentation/user-guide/creating-workflows.html#catalogs)\n",
    "\n",
    "\n",
    "## Site Catalog\n",
    "\n",
    "The Site Catalog defines the computational environments where the workflow's tasks will execute. Each \"site\" in the catalog represents a distinct resource, such as a local machine, high-performance computing cluster, or cloud platform. The catalog provides detailed information about the resources at each site, including paths for shared and local storage, ensuring efficient data management by defining where input, output, and intermediate data will be stored and how they will be staged in and out of the site.\n",
    "\n",
    "The example from the previous workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1a58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # --- Site Catalog -------------------------------------------------------------\n",
    "    def create_sites_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.sc = SiteCatalog()\n",
    "\n",
    "        local = (Site(\"local\")\n",
    "                    .add_directories(\n",
    "                        Directory(Directory.SHARED_SCRATCH, self.shared_scratch_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.shared_scratch_dir, Operation.ALL)),\n",
    "                        Directory(Directory.LOCAL_STORAGE, self.local_storage_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.local_storage_dir, Operation.ALL))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        condorpool = (Site(exec_site_name)\n",
    "                        .add_condor_profile(universe=\"container\")\n",
    "                        .add_pegasus_profile(\n",
    "                            style=\"condor\"\n",
    "                        )\n",
    "                    )\n",
    "        condorpool.add_profiles(Namespace.ENV, LANG='C')\n",
    "        condorpool.add_profiles(Namespace.ENV, PYTHONUNBUFFERED='1')\n",
    "        \n",
    "        # exclude the ACCESS Pegasus TestPool \n",
    "        #condorpool.add_condor_profile(requirements=\"TestPool =!= True\")\n",
    "\n",
    "        # If you want to run on OSG, please specify your OSG ProjectName. For testing, feel\n",
    "        # free to use the USC_Deelman project (the PI of the Pegasus project).For\n",
    "        # production work, please use your own project.\n",
    "        condorpool.add_profiles(Namespace.CONDOR, key=\"+ProjectName\", value=\"\\\"USC_Deelman\\\"\")\n",
    "        \n",
    "        self.sc.add_sites(local, condorpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fa8f5",
   "metadata": {},
   "source": [
    "The _local_ site refers to the submit host, and is always required. In this case we specify two directories, one scratch directory for the workflow to use during the execution, and one long term storage to be use for outputs.\n",
    "\n",
    "The _condorpool_ site refers to the HTCondor pool we want to run our jobs in. There is no need to specify directories in this case, as the work directory is automatically assigned by HTCondor.\n",
    "\n",
    "Note how we also set profiles on the _condorpool_ site. There are both environment and HTCondor profiles specified, and they will be applied to all jobs on that site. See the [Configuration](https://pegasus.isi.edu/documentation/reference-guide/configuration.html) chapter in the Pegasus manual.\n",
    "\n",
    "## Transformation Catalog\n",
    "\n",
    "The Transformation Catalog serves as a repository of metadata that describes the transformations or executables used within a workflow. Each transformation represents a computational task, such as a container, script, or binary, that will be executed as part of the workflow. The catalog provides essential information about these transformations, including their unique names, versions, and the locations where they are installed or can be accessed. Additionally, the Transformation Catalog can include details about how transformations should be staged, for example, whether they should be transferred to the execution site or executed in place.\n",
    "\n",
    "In our example workflow, we have a container containing the LLM model and code. The container is hosted on Open Storage Network (OSN), and is a good example how Pegasus can transfer data as part of the workflow. The container is pulled down with a data transfer job in the workflow.\n",
    "\n",
    "The code we want to run is defined as a `Transformation()`, referencing the container. We also set profiles to specify our resource requirements (1 CPU core, 1 GPU, 10 GB RAM, and 15 GB disk), as well what type GPU we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e390bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # --- Transformation Catalog (Executables and Containers) ----------------------\n",
    "    def create_transformation_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.tc = TransformationCatalog()\n",
    "        \n",
    "        llm_rag_container = Container(\"llm_rag_container\",\n",
    "            container_type = Container.SINGULARITY,\n",
    "            image = \"https://usgs2.osn.mghpcc.org/pegasus-tutorials/containers/llm-rag-v2.sif\",\n",
    "            image_site = \"web\"\n",
    "        )\n",
    "        \n",
    "        # main job wrapper\n",
    "        # note how gpus and other resources are requested\n",
    "        wrapper = Transformation(\"wrapper\", \n",
    "                                 site=\"local\", \n",
    "                                 pfn=self.wf_dir+\"/bin/wrapper.sh\", \n",
    "                                 is_stageable=True, \n",
    "                                 container=llm_rag_container)\\\n",
    "                  .add_pegasus_profiles(cores=1, gpus=1, memory=\"10 GB\", diskspace=\"15 GB\")\\\n",
    "                  .add_profiles(Namespace.CONDOR, key=\"require_gpus\", value=\"Capability >= 8.0\")\n",
    "\n",
    "        \n",
    "        self.tc.add_containers(llm_rag_container)\n",
    "        self.tc.add_transformations(wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2245260",
   "metadata": {},
   "source": [
    "## Replica Catalog\n",
    "\n",
    "The Replica Catalog acts as a mapping between **logical file names (LFNs)** and their corresponding **physical file locations (PFNs)** across various storage systems. It is a critical component that helps Pegasus locate the data needed for a workflow's execution. Logical file names are workflow-specific identifiers used to reference input, intermediate, or output files, while physical file names represent their actual paths or URLs on storage resources, such as local disks, shared filesystems, cloud storage, or remote servers. The Replica Catalog ensures that Pegasus can find and retrieve the required data efficiently, regardless of where it is stored. It supports multiple storage protocols, such as HTTP, S3, GridFTP, and SCP, making it highly flexible and adaptable to diverse infrastructures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601311bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # --- Replica Catalog ----------------------------------------------------------\n",
    "    def create_replica_catalog(self):\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        # Add inference dependencies\n",
    "        self.rc.add_replica(\"local\", \"llm-rag.py\", \\\n",
    "                                     os.path.join(self.wf_dir, \"bin/llm-rag.py\"))\n",
    "        self.rc.add_replica(\"local\", \"Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt\", \\\n",
    "                                     os.path.join(self.wf_dir, \"inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c0dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
