{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "**Objective:** Familiarize users with the Pegasus workflow API, by extending a provide LLM-RAG example to process a set of files from an input/ directory.\n",
    "\n",
    "In this tutorial we will extend the workflow from the prevsious tutorial, which only processed a single book, to process all the books provided in the `inputs/` directory. The modifications should include a `for` loop to add the books to the replica catalog, and another `for` loop to add a job for each book. \n",
    "\n",
    "A hint is to use the Python `glob` module to list all the files with the `.txt` extension. Run the next cell to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "for f in glob.glob('inputs/*.txt'):\n",
    "    print(os.path.basename(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further help with this task:\n",
    "\n",
    " - The Pegasus API is described in the [documentation](https://pegasus.isi.edu/documentation/python/Pegasus.api.html)\n",
    " - Comments have been added in the code below. See the `create_replica_catalog()` and `create_workflow()` methods.\n",
    " - There is an additional step below creating an image of the generated workflow - for the extended workflow, this image should have 5 nodes, and input files\n",
    " - If you get stuck, the solution can be found in the `solutions.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from Pegasus.api import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class LLMRAGBooks:\n",
    "    \n",
    "    BASE_DIR = Path(\".\").resolve()\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.props = Properties()\n",
    "\n",
    "        self.wf = Workflow(\"llm-rag-books\")\n",
    "        self.tc = TransformationCatalog()\n",
    "        self.sc = SiteCatalog()\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        self.wf.add_transformation_catalog(self.tc)\n",
    "        self.wf.add_site_catalog(self.sc)\n",
    "        self.wf.add_replica_catalog(self.rc)\n",
    "        \n",
    "        self.wf_dir = str(Path(\".\").resolve())\n",
    "        self.shared_scratch_dir = os.path.join(self.wf_dir, \"scratch\")\n",
    "        self.local_storage_dir = os.path.join(self.wf_dir, \"output\")\n",
    "    \n",
    "    \n",
    "    # --- Write files in directory -------------------------------------------------\n",
    "    def write(self):\n",
    "        self.props.write()\n",
    "        self.sc.write()\n",
    "        self.rc.write()\n",
    "        self.tc.write()\n",
    "        \n",
    "        try:\n",
    "            self.wf.write()\n",
    "            # also graph the workflow\n",
    "            self.wf.graph(include_files=True,  label=\"xform\", output=\"graph.png\")\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    # --- Plan and Submit the workflow ----------------------------------------------\n",
    "    def plan_submit(self):\n",
    "        try:\n",
    "            self.wf.plan(submit=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Get status of the workflow -----------------------------------------------\n",
    "    def status(self):\n",
    "        try:\n",
    "            self.wf.status(long=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "\n",
    "            \n",
    "    # --- Wait for the workflow to finish -----------------------------------------------\n",
    "    def wait(self):\n",
    "        try:\n",
    "            self.wf.wait()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Get statistics of the workflow -----------------------------------------------\n",
    "    def statistics(self):\n",
    "        try:\n",
    "            self.wf.statistics()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Configuration (Pegasus Properties) ---------------------------------------\n",
    "    def create_pegasus_properties(self):\n",
    "        \n",
    "        # Help Pegasus developers by sharing performance data (optional)\n",
    "        self.props[\"pegasus.monitord.encoding\"] = \"json\"\n",
    "        self.props[\"pegasus.catalog.workflow.amqp.url\"] = \"amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows\"\n",
    "\n",
    "        # nicer looking submit dirs\n",
    "        self.props[\"pegasus.dir.useTimestamp\"] = \"true\"\n",
    "\n",
    "        \n",
    "    # --- Site Catalog -------------------------------------------------------------\n",
    "    def create_sites_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.sc = SiteCatalog()\n",
    "\n",
    "        local = (Site(\"local\")\n",
    "                    .add_directories(\n",
    "                        Directory(Directory.SHARED_SCRATCH, self.shared_scratch_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.shared_scratch_dir, Operation.ALL)),\n",
    "                        Directory(Directory.LOCAL_STORAGE, self.local_storage_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.local_storage_dir, Operation.ALL))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        condorpool = (Site(exec_site_name)\n",
    "                        .add_condor_profile(universe=\"container\")\n",
    "                        .add_pegasus_profile(\n",
    "                            style=\"condor\"\n",
    "                        )\n",
    "                    )\n",
    "        condorpool.add_profiles(Namespace.ENV, LANG='C')\n",
    "        condorpool.add_profiles(Namespace.ENV, PYTHONUNBUFFERED='1')\n",
    "        \n",
    "        # exclude the ACCESS Pegasus TestPool \n",
    "        #condorpool.add_condor_profile(requirements=\"TestPool =!= True\")\n",
    "\n",
    "        # If you want to run on OSG, please specify your OSG ProjectName. For testing, feel\n",
    "        # free to use the USC_Deelman project (the PI of the Pegasus project).For\n",
    "        # production work, please use your own project.\n",
    "        condorpool.add_profiles(Namespace.CONDOR, key=\"+ProjectName\", value=\"\\\"USC_Deelman\\\"\")\n",
    "        \n",
    "        self.sc.add_sites(local, condorpool)\n",
    "        \n",
    "\n",
    "    # --- Transformation Catalog (Executables and Containers) ----------------------\n",
    "    def create_transformation_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.tc = TransformationCatalog()\n",
    "        \n",
    "        llm_rag_container = Container(\"llm_rag_container\",\n",
    "            container_type = Container.SINGULARITY,\n",
    "            image = \"https://usgs2.osn.mghpcc.org/pegasus-tutorials/containers/llm-rag-v2.sif\",\n",
    "            image_site = \"web\"\n",
    "        )\n",
    "        \n",
    "        # main job wrapper\n",
    "        # note how gpus and other resources are requested\n",
    "        wrapper = Transformation(\"wrapper\", \n",
    "                                 site=\"local\", \n",
    "                                 pfn=self.wf_dir+\"/bin/wrapper.sh\", \n",
    "                                 is_stageable=True, \n",
    "                                 container=llm_rag_container)\\\n",
    "                  .add_pegasus_profiles(cores=1, gpus=1, memory=\"10 GB\", diskspace=\"15 GB\")\\\n",
    "                  .add_profiles(Namespace.CONDOR, key=\"require_gpus\", value=\"Capability >= 8.0\")\n",
    "\n",
    "        \n",
    "        self.tc.add_containers(llm_rag_container)\n",
    "        self.tc.add_transformations(wrapper)\n",
    "\n",
    "    \n",
    "    # --- Replica Catalog ----------------------------------------------------------\n",
    "    def create_replica_catalog(self):\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        # Add inference dependencies\n",
    "        self.rc.add_replica(\"local\", \"llm-rag.py\", \\\n",
    "                                     os.path.join(self.wf_dir, \"bin/llm-rag.py\"))\n",
    "        \n",
    "        # TUTORIAL: make sure that all the files in the inputs/ directory are\n",
    "        # added to the replica catalog\n",
    "        for f in glob.glob(\"inputs/*.txt\"):\n",
    "            fname = os.path.basename(f)\n",
    "            self.rc.add_replica(\"local\", fname, f\"{self.wf_dir}/inputs/{fname}\")\n",
    "     \n",
    "\n",
    "    # --- Create Workflow ----------------------------------------------------------\n",
    "    def create_workflow(self):\n",
    "        self.wf = Workflow(name=\"llm-rag-books\", infer_dependencies=True)\n",
    "        \n",
    "        # existing files - already listed in the replica catalog\n",
    "        llm_rag_py = File(\"llm-rag.py\")\n",
    "        \n",
    "        # TUTORIAL: glob over the files in inputs/ and create a job per\n",
    "        # file. You will also have to create unique output file per job\n",
    "        # (already named uniquely)\n",
    "        for f in glob.glob(\"inputs/*.txt\"):\n",
    "            fname = os.path.basename(f)            \n",
    "\n",
    "            book = File(fname)\n",
    "        \n",
    "            # these will be generated by the workflow\n",
    "            answers_txt = File(f\"{book}-answers.txt\")\n",
    "            ollama_log = File(f\"{book}-ollama.log\")\n",
    "        \n",
    "            job = (Job(\"wrapper\")\n",
    "                        .add_args(book)\n",
    "                        .add_inputs(llm_rag_py, book)\n",
    "                        .add_outputs(answers_txt, stage_out=True)\n",
    "                        .add_outputs(ollama_log, stage_out=True)\n",
    "                  )\n",
    "        \n",
    "            self.wf.add_jobs(job)\n",
    "\n",
    "            \n",
    "workflow = LLMRAGBooks()\n",
    "\n",
    "print(\"Creating execution sites...\")\n",
    "workflow.create_sites_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating workflow properties...\")\n",
    "workflow.create_pegasus_properties()\n",
    "\n",
    "print(\"Creating transformation catalog...\")\n",
    "workflow.create_transformation_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating replica catalog...\")\n",
    "workflow.create_replica_catalog()\n",
    "\n",
    "print(\"Creating workflow dag...\")\n",
    "workflow.create_workflow()\n",
    "\n",
    "workflow.write()\n",
    "print(\"Workflow has been generated!\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the generated workflow\n",
    "\n",
    "You should get an image with 6 nodes, one for each book, and rectangles indicating data in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning the Workflow\n",
    "\n",
    "The next step is to plan the workflow, which means Pegasus takes an abstract workflow - a high-level representation of tasks, dependencies, and required resources - and transforms it into an executable workflow tailored for the target execution environment.\n",
    "\n",
    "We will also save a step here, and submit the planned workflow in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.plan_submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the planning phase includes example command-line commands for monitoring and interacting with the workflow. While these commands are always available, you can also use the Python `workflow` object directly within the notebook. This object provides detailed insights into the workflow's status, including the number of jobs in each state (e.g., idle, running, or completed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for the workflow to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Results\n",
    "\n",
    "Once the workflow has finished, we can look at the answers file for our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat output/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "The next tutorial will cover Pegasus catalogs, which describes the execution enviroment, software availability, and where to find input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
