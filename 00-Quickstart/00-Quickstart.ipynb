{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Guide\n",
    "\n",
    "Welcome to the Pegasus quickstart notebook, which is intended for new users who want to get a quick overview of Pegasus concepts and usage. \n",
    "\n",
    "In this notebook, we cover\n",
    "\n",
    " - Using the Pegasus API to generate an abstract workflow\n",
    " - Using the API to plan the abstract workflow into an executable workflow and submit it\n",
    " - Monitor the workflow and get runtime statistics\n",
    " \n",
    "## No Allocation Required\n",
    "\n",
    "Typically, using ACCESS Pegasus to run workflows necessitates users to link their own allocations. However, the initial notebooks in this guide are pre-configured to operate on a modest resource bundled with ACCESS Pegasus. As you progress to more complex sample workflows, such as Variant Calling, you'll be required to utilize your own allocation.\n",
    "\n",
    "## Diamond Workflow\n",
    "\n",
    "This notebook will generate the **diamond workflow** illustrated below, then plan and execute the workflow on the local condorpool. Rectangles represent input/output files, and ovals represent compute jobs. The arrows represent file dependencies between each compute job. \n",
    "\n",
    "![Diamond Workflow](../images/diamond.svg)\n",
    "\n",
    "The abstract workflow description that you specify to Pegasus is portable, and usually does not contain any locations to physical input files, executables or end points where jobs are executed. Pegasus uses three information catalogs during the planning process.In this quickstart guide, we will not configure any of the above 3 catalogs. Instead, we will\n",
    "\n",
    "- provide hints in the jobs in the abstract workflow as to the locations of the executables\n",
    "- Pegasus will pick up the locations on input data from an input directory and place the outputs to an output directory. \n",
    "- the workflows will run on a default compute site named **condorpool**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pegasus.api import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "\n",
    "INPUT_DIR=\"./inputs\"\n",
    "Path(INPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "with open( INPUT_DIR + \"/\" + \"f.a\", \"w\") as f:\n",
    "    f.write(\"This is the contents of the input file for the diamond workflow!\")\n",
    "\n",
    "# --- Workflow -----------------------------------------------------------------\n",
    "wf = Workflow(\"blackdiamond\")\n",
    "\n",
    "props = Properties()\n",
    "# Allow the jobs to run on the test cluster. You do not need to provision\n",
    "# resources from your own allocations in this case, but the cluster is small\n",
    "# and should not be used for production workloads.\n",
    "props.add_site_profile(\"condorpool\", \"condor\", \"+run_on_test_cluster\", \"true\")\n",
    "props.write()\n",
    "\n",
    "fa  = File(\"f.a\")\n",
    "fb1 = File(\"f.b1\")\n",
    "fb2 = File(\"f.b2\")\n",
    "job_preprocess = Job(\"preprocess\", node_label=\"preprocess\")\\\n",
    "                    .add_args(\"-a\", \"preprocess\", \"-T\", \"3\", \"-i\", fa, \"-o\", fb1, fb2)\\\n",
    "                    .add_inputs(fa)\\\n",
    "                    .add_outputs(fb1, fb2)\n",
    "\n",
    "fc1 = File(\"f.c1\")\n",
    "job_findrange_1 = Job(\"findrange\", node_label=\"findrange\")\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb1, \"-o\", fc1)\\\n",
    "                    .add_inputs(fb1)\\\n",
    "                    .add_outputs(fc1)\n",
    "\n",
    "fc2 = File(\"f.c2\")\n",
    "job_findrange_2 = Job(\"findrange\", node_label=\"findrange\")\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb2, \"-o\", fc2)\\\n",
    "                    .add_inputs(fb2)\\\n",
    "                    .add_outputs(fc2)\n",
    "\n",
    "fd = File(\"f.d\")\n",
    "job_analyze = Job(\"analyze\", node_label=\"analyze\")\\\n",
    "                .add_args(\"-a\", \"analyze\", \"-T\", \"3\", \"-i\", fc1, fc2, \"-o\", fd)\\\n",
    "                .add_inputs(fc1, fc2)\\\n",
    "                .add_outputs(fd)\n",
    "\n",
    "wf.add_jobs(job_preprocess, job_findrange_1, job_findrange_2, job_analyze)\n",
    "\n",
    "# write out the workflow to files, and graph it\n",
    "try:\n",
    "    wf.write()\n",
    "    wf.graph(include_files=True,  output=\"graph.png\")\n",
    "except PegasusClientError as e:\n",
    "    print(e)\n",
    "\n",
    "# view rendered workflow\n",
    "from IPython.display import Image\n",
    "Image(filename='graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the workflow\n",
    "# note the use of transformations_dir argument. that tells pegasus the directory where your executables are\n",
    "try:\n",
    "    wf.plan(input_dirs=[INPUT_DIR], output_dir=\"./outputs\", transformations_dir=\"./executables\", submit=True)\\\n",
    "        .wait()\n",
    "except PegasusClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What's Next?\n",
    "\n",
    "To continue exploring Pegasus, and specifically learn how to run the same workflow using your ACCESS allocation, please open the notebook in `01-Introduction/` . The introduction chapter will make you run the same diamond workflow. But this time around, it walks you through on how to setup your\n",
    "\n",
    "- Replica Catalog to provide locations to datasets that are not available on the locally.\n",
    "- Transformation Catalog to define executables and the container in which the executable is supposed to run\n",
    "- Site Catalog to describe directories to use for data staging.\n",
    "- Tie in your ACCESS allocation to running your workflows on supported ACCESS resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
