{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e243d342",
   "metadata": {},
   "source": [
    "# Orcasound Pegasus Workflow\n",
    "\n",
    "The [Ocean Observatories Initiative (OOI)](https://oceanobservatories.org/), through a network of sensors, supports critical research in ocean science and marine life. [Orcasound](https://www.orcasound.net/) is a community driven project that leverages hydrophone sensors deployed in **three locations** in the state of **Washington** (San Juan Island, Point Bush, and Port Townsend as shown in the figure below) in order to study Orca whales in the Pacific Northwest region.\n",
    "\n",
    "Throughout the course of this project, code to process and analyze the hydrophone data has been developed, and machine learning models have been trained to automatically identify the whistles of the Orcas. All of the code is available publicly on GitHub, and the hydrophone data are free to access, stored in an **AWS S3** bucket. In this paper, we have developed an Orcasound workflow using Pegasus. This version of the pipeline is based on the [Orcasound GitHub actions](https://github.com/orcasound/orca-action-workflow) workflow, and incorporates inference components of the [OrcaHello AI](https://github.com/orcasound/aifororcas-livesystem) notification system.\n",
    "\n",
    "The workflow processes the hydrophone data of one or more sensors in batches for each timestamp, and converts them to a WAV format. Using the WAV output it creates spectrogram images that are stored in the final output location. Furthermore, using the pretrained Orcasound model, the workflow scans the WAV files to identify potential sounds produced by the orcas. These predictions are merged into a JSON file for each sensor, and if data from more than one sensor are being processed, the workflow will create a final merged JSON output for all. In our experiments, we used data from a single hydrophone sensor over the span of a day.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/orca_sound_sensors.png\" style=\"width: 400px;\"/>\n",
    "<br>\n",
    "\n",
    "**Machine Learning steps in the workflow :**\n",
    "<br>\n",
    "<img src=\"images/ml_steps2.png\" style=\"width: 500px;\"/>\n",
    "<br>\n",
    "\n",
    "## Containers\n",
    "All tools required to execute the jobs are all included in two containers available on Dockerhub : \n",
    "<br>[Orcasound Container](https://hub.docker.com/r/papajim/orcasound-processing) which runs on python defined in `Docker/Orca_Dockerfile` with the basic tools - \n",
    "* awscli\n",
    "* matplotlib\n",
    "* scipy\n",
    "* m3u8\n",
    "\n",
    "<br>[Orcasound ML Processing Container](https://hub.docker.com/r/papajim/orcasound-ml-processing) which runs on python and uses some additional machine learning libraries (including the aforementioned ones) defined in `Docker/Orca_ML_Dockerfile` as -\n",
    "* scikit-learn\n",
    "* torch\n",
    "* torchvision\n",
    "* pytorchtools\n",
    "* torch-summary\n",
    "* librosa\n",
    "\n",
    "\n",
    "## Accessing the Input Data\n",
    "The hydrophone data recordings are free to access and reside in an **AWS S3** bucket, thus no setup is required regarding it.\n",
    "\n",
    "\n",
    "## Workflow\n",
    "The workflow processes and analyzes the hydrophone data and uses trained machine learning models to automatically identify the whistles of the Orcas.\n",
    "\n",
    "![Pegasus Orcasound Workflow graph](images/orcasound-workflow.png)\n",
    "\n",
    "<br>The descriptions for various jobs in the worklfow are listed in a table below\n",
    "\n",
    "| Job Label                 | Description                                      |\n",
    "| --------------------------|--------------------------------------------------|\n",
    "| convert2wav               | converts the input hydrophone data to WAV format |\n",
    "| convert2spectrogram       | converts the WAV output to spectrogram images    |\n",
    "| inference                 | identifies the sound using a pretrained ML model |\n",
    "| merge predictions         | merges the predictions from all sensors          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcc775",
   "metadata": {},
   "source": [
    "## 1. Create the Orcasound Workflow\n",
    "\n",
    "By now, you have a good idea about the Pegasus Workflow API.\n",
    "We now create the workflow for the Orcasound prediction based on the picture above\n",
    "\n",
    "First step is to update your AWS account username, and then enter the range of dates which will be used\n",
    "to extract the hydrophone data from the main public database from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the sensor names in list format, choices from : [\"rpi_bush_point\",\"rpi_port_townsend\",\"rpi_orcasound_lab\"]\n",
    "SENSORS = ['rpi_bush_point']\n",
    "\n",
    "# update the start and end dates regarding the data to be extracted from sensors\n",
    "START_DATE = '2021-08-10'\n",
    "# default end date is set as +1 day\n",
    "END_DATE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74105b4f",
   "metadata": {},
   "source": [
    "**Note:** End date from the dataset is set to be limited upto a maximum of 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bcacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# --- Import Pegasus API -----------------------------------------------------------\n",
    "from Pegasus.api import *\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# --- Main workflow class ----------------------------------------------------------\n",
    "class OrcasoundWorkflow():\n",
    "    wf = None\n",
    "    sc = None\n",
    "    tc = None\n",
    "    rc = None\n",
    "    props = None\n",
    "\n",
    "    dagfile = None\n",
    "    wf_dir = None\n",
    "    shared_scratch_dir = None\n",
    "    local_storage_dir = None\n",
    "    wf_name = \"orcasound\"\n",
    "    \n",
    "    #data details in order to pull data from public s3 bucket\n",
    "    s3_cache = None\n",
    "    s3_files = None\n",
    "    s3_bucket = \"streaming-orcasound-net\"\n",
    "    s3_cache_location = \".s3_cache\"\n",
    "    s3_cache_file = \".s3_cache/streaming-orcasound-net-7-days.csv\"\n",
    "    s3_cache_xz = \"streaming-orcasound-net-7-days.tar.xz\"\n",
    "    #data catalog url, used to filter out the data from the main dataset stored in S3 bucket\n",
    "    s3_cache_xz_url = \"https://workflow.isi.edu/Panorama/Data/Orcasound/streaming-orcasound-net-7-days.tar.xz\"\n",
    "    \n",
    "    # --- Init ---------------------------------------------------------------------\n",
    "    def __init__(self, sensors, start_date, end_date, max_files, dagfile=\"workflow.yml\"):\n",
    "        self.dagfile = dagfile\n",
    "        self.wf_dir = str(Path(\".\").resolve())\n",
    "        self.shared_scratch_dir = os.path.join(self.wf_dir, \"scratch\")\n",
    "        self.local_storage_dir = os.path.join(self.wf_dir, \"output\")\n",
    "        self.sensors = sensors\n",
    "        self.max_files = max_files\n",
    "        self.start_date = int(start_date.timestamp())\n",
    "        self.end_date = int(end_date.timestamp())\n",
    "\n",
    "    \n",
    "    # --- Write files in directory -------------------------------------------------\n",
    "    def write(self):\n",
    "        if not self.sc is None:\n",
    "            self.sc.write()\n",
    "        self.props.write()\n",
    "        self.rc.write()\n",
    "        self.tc.write()\n",
    "        \n",
    "        try:\n",
    "            self.wf.write()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    # --- Plan and Submit the workflow ----------------------------------------------\n",
    "    def plan_submit(self):\n",
    "        try:\n",
    "            self.wf.plan(submit=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Get status of the workflow -----------------------------------------------\n",
    "    def status(self):\n",
    "        try:\n",
    "            self.wf.status(long=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "    # --- Get statistics of the workflow -----------------------------------------------\n",
    "    def statistics(self):\n",
    "        try:\n",
    "            self.wf.statistics()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "    # --- Configuration (Pegasus Properties) ---------------------------------------\n",
    "    def create_pegasus_properties(self):\n",
    "        self.props = Properties()\n",
    "        self.props[\"pegasus.transfer.threads\"] = \"16\"\n",
    "        return\n",
    "\n",
    "\n",
    "    # --- Site Catalog -------------------------------------------------------------\n",
    "    def create_sites_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.sc = SiteCatalog()\n",
    "\n",
    "        local = (Site(\"local\")\n",
    "                    .add_directories(\n",
    "                        Directory(Directory.SHARED_SCRATCH, self.shared_scratch_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.shared_scratch_dir, Operation.ALL)),\n",
    "                        Directory(Directory.LOCAL_STORAGE, self.local_storage_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.local_storage_dir, Operation.ALL))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        exec_site = (Site(exec_site_name)\n",
    "                        .add_condor_profile(universe=\"vanilla\")\n",
    "                        .add_pegasus_profile(\n",
    "                            style=\"condor\"\n",
    "                        )\n",
    "                    )\n",
    "        self.sc.add_sites(local, exec_site)\n",
    "        \n",
    "\n",
    "    # --- Transformation Catalog (Executables and Containers) ----------------------\n",
    "    def create_transformation_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.tc = TransformationCatalog()\n",
    "        \n",
    "        orcasound_container = Container(\"orcasound_container\",\n",
    "            container_type = Container.SINGULARITY,\n",
    "            image=\"docker://papajim/orcasound-processing:latest\",\n",
    "            image_site=\"docker_hub\"\n",
    "        )\n",
    "        \n",
    "        orcasound_ml_container = Container(\"orcasound_ml_container\",\n",
    "            container_type = Container.SINGULARITY,\n",
    "            image=\"docker://papajim/orcasound-ml-processing:latest\",\n",
    "            image_site=\"docker_hub\"\n",
    "        )\n",
    "\n",
    "        # Add the orcasound processing\n",
    "        mkdir = Transformation(\"mkdir\", site=\"local\", pfn=\"/bin/mkdir\", is_stageable=False)\n",
    "        # converts the input hydrophone data to WAV format\n",
    "        convert2wav = Transformation(\"convert2wav\", site=exec_site_name, pfn=os.path.join(self.wf_dir, \"bin/convert2wav.py\"), is_stageable=True, container=orcasound_container)\n",
    "        # converts the WAV output to spectrogram images\n",
    "        convert2spectrogram = Transformation(\"convert2spectrogram\", site=exec_site_name, pfn=os.path.join(self.wf_dir, \"bin/convert2spectrogram.py\"), is_stageable=True, container=orcasound_container)\n",
    "        # identifies the sound using a pretrained ML model\n",
    "        inference = Transformation(\"inference\", site=exec_site_name, pfn=os.path.join(self.wf_dir, \"bin/inference.py\"), is_stageable=True, container=orcasound_ml_container)\n",
    "        # merges the predictions from all sensors\n",
    "        merge = Transformation(\"merge\", site=exec_site_name, pfn=os.path.join(self.wf_dir, \"bin/merge.py\"), is_stageable=True, container=orcasound_container)\n",
    "\n",
    "        \n",
    "        self.tc.add_containers(orcasound_container, orcasound_ml_container)\n",
    "        self.tc.add_transformations(convert2wav, convert2spectrogram, inference, merge, mkdir)\n",
    "\n",
    "    \n",
    "    # --- Fetch s3 catalog ---------------------------------------------------------\n",
    "    def fetch_s3_catalog(self):\n",
    "        print(\"Downloading S3 cache...\")\n",
    "        data = requests.get(self.s3_cache_xz_url)\n",
    "        if data.status_code != 200:\n",
    "            raise ConnectionError(\"Download for {} failed with error code: {}\".format(self.s3_cache_xz_url, data.status_code))\n",
    "\n",
    "        with open(self.s3_cache_xz, \"wb\") as f:\n",
    "            f.write(data.content)\n",
    "\n",
    "        print(\"Unpacking S3 cache...\")\n",
    "        with tarfile.open(self.s3_cache_xz) as f:\n",
    "            f.extractall('.')\n",
    "\n",
    "        os.remove(self.s3_cache_xz)\n",
    "        print(\"S3 cache fetched successfully...\")\n",
    "\n",
    "\n",
    "    # --- Check s3 catalog for files -----------------------------------------------\n",
    "    def check_s3_cache(self):\n",
    "        s3_files = self.s3_cache[self.s3_cache[\"Sensor\"].isin(self.sensors) & (self.s3_cache[\"Timestamp\"] >= self.start_date) & (self.s3_cache[\"Timestamp\"] <= self.end_date)]\n",
    "\n",
    "        if s3_files.empty:\n",
    "            print(\"No files found for sensors between {} and {}\".format(self.start_date, self.end_date))\n",
    "            exit()\n",
    "\n",
    "        for sensor in self.sensors:\n",
    "            if s3_files[s3_files[\"Sensor\"] == sensor].empty:\n",
    "                print(\"No files found for sensor {} between {} and {}\".format(sensor, self.start_date, self.end_date))\n",
    "        \n",
    "        self.s3_files = s3_files\n",
    "\n",
    "\n",
    "    # --- Read s3 catalog files ----------------------------------------------------\n",
    "    def read_s3_cache(self):\n",
    "        if not os.path.isfile(self.s3_cache_file):\n",
    "            self.fetch_s3_catalog()\n",
    "        \n",
    "        print(\"Reading S3 cache...\")\n",
    "        self.s3_cache = pd.read_csv(self.s3_cache_file)\n",
    "        self.check_s3_cache()\n",
    "\n",
    "    \n",
    "    # --- Replica Catalog ----------------------------------------------------------\n",
    "    def create_replica_catalog(self):\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        self.read_s3_cache()\n",
    "        if (self.s3_files is None):\n",
    "            exit()\n",
    "\n",
    "        # Add s3 files as deep lfns\n",
    "        for f in self.s3_files[\"Key\"]:\n",
    "            self.rc.add_replica(\"AmazonS3\", f, \"https://streaming-orcasound-net.s3.us-west-2.amazonaws.com/{}\".format(f))\n",
    "\n",
    "        # Add inference dependencies\n",
    "        self.rc.add_replica(\"local\", \"model.py\", os.path.join(self.wf_dir, \"bin/model.py\"))\n",
    "        self.rc.add_replica(\"local\", \"dataloader.py\", os.path.join(self.wf_dir, \"bin/dataloader.py\"))\n",
    "        self.rc.add_replica(\"local\", \"params.py\", os.path.join(self.wf_dir, \"bin/params.py\"))\n",
    "        self.rc.add_replica(\"local\", \"model.pkl\", os.path.join(self.wf_dir, \"input/model.pkl\"))\n",
    "     \n",
    "\n",
    "    # --- Create Workflow ----------------------------------------------------------\n",
    "    def create_workflow(self):\n",
    "        self.wf = Workflow(self.wf_name, infer_dependencies=True)\n",
    "        \n",
    "        model_py = File(\"model.py\")\n",
    "        dataloader_py = File(\"dataloader.py\")\n",
    "        params_py = File(\"params.py\")\n",
    "        model_file = File(\"model.pkl\")\n",
    "\n",
    "        # Create a job for each Sensor and Timestamp\n",
    "        predictions_files = []\n",
    "        # Creating a linear pipeline of convert2wav-->convert2spectrogram-->predict\n",
    "        # regarding each sensor and timestamp\n",
    "        for sensor in self.sensors:\n",
    "            predictions_sensor_files = []\n",
    "            for ts in self.s3_files[self.s3_files[\"Sensor\"] == sensor][\"Timestamp\"].unique():\n",
    "                predictions_sensor_ts_files = []\n",
    "                sensor_ts_files = self.s3_files[(self.s3_files[\"Sensor\"] == sensor) & (self.s3_files[\"Timestamp\"] == ts) & (self.s3_files[\"Filename\"] != \"live.m3u8\")]\n",
    "                sensor_ts_files_len = len(sensor_ts_files.index)\n",
    "                # -2 if m3u8 in the list else -1\n",
    "                sensor_ts_files = sensor_ts_files[sensor_ts_files[\"Filename\"] != \"live{}.ts\".format(sensor_ts_files_len-1)]\n",
    "                sensor_ts_files_len -= 1\n",
    "\n",
    "                num_of_splits = -(-sensor_ts_files_len//self.max_files)\n",
    "\n",
    "                mkdir_job = (Job(\"mkdir\", _id=\"scratch_mkdir_{0}_{1}\".format(sensor, ts), node_label=\"scratch_mkdir_{0}_{1}\".format(sensor, ts))\n",
    "                                .add_args(\"-p ${0}/png/{1}/{2} ${0}/wav/{1}/{2}\".format(\"_PEGASUS_INITIAL_DIR\", sensor, ts))\n",
    "                                .add_profiles(Namespace.SELECTOR, key=\"execution.site\", value=\"local\")\n",
    "                )\n",
    "                self.wf.add_jobs(mkdir_job)\n",
    "\n",
    "                counter = 1\n",
    "                for job_files in np.array_split(sensor_ts_files, num_of_splits):\n",
    "                    input_files = job_files[\"Key\"]\n",
    "                    wav_files = []\n",
    "                    png_files = []\n",
    "                    for f in job_files[\"Filename\"]:\n",
    "                        wav_files.append(\"wav/{0}/{1}/{2}\".format(sensor, ts, f.replace(\".ts\", \".wav\")))\n",
    "                        png_files.append(\"png/{0}/{1}/{2}\".format(sensor, ts, f.replace(\".ts\", \".png\")))\n",
    "                \n",
    "                    convert2wav_job = (Job(\"convert2wav\", _id=\"wav_{0}_{1}_{2}\".format(sensor, ts, counter), node_label=\"wav_{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                        .add_args(\"-i {0}/hls/{1} -o wav/{0}/{1}\".format(sensor, ts))\n",
    "                                        .add_inputs(*input_files, bypass_staging=True)\n",
    "                                        .add_outputs(*wav_files, stage_out=False, register_replica=False)\n",
    "                                        .add_pegasus_profiles(label=\"{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                    )\n",
    "                    \n",
    "                    convert2spectrogram_job = (Job(\"convert2spectrogram\", _id=\"png_{0}_{1}_{2}\".format(sensor, ts, counter), node_label=\"spectrogram_{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                        .add_args(\"-i wav/{0}/{1} -o png/{0}/{1}\".format(sensor, ts))\n",
    "                                        .add_inputs(*wav_files)\n",
    "                                        .add_outputs(*png_files, stage_out=True, register_replica=False)\n",
    "                                        .add_pegasus_profiles(label=\"{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                    )\n",
    "                    \n",
    "                    predictions = File(\"predictions_{0}_{1}_{2}.json\".format(sensor, ts, counter))\n",
    "                    predictions_sensor_ts_files.append(predictions)\n",
    "                    inference_job = (Job(\"inference\", _id=\"predict_{0}_{1}_{2}\".format(sensor, ts, counter), node_label=\"inference_{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                        .add_args(\"-i wav/{0}/{1} -s {0} -t {1} -m {3} -o predictions_{0}_{1}_{2}.json\".format(sensor, ts, counter, model_file.lfn))\n",
    "                                        .add_inputs(model_file, model_py, dataloader_py, params_py, *wav_files)\n",
    "                                        .add_outputs(predictions, stage_out=False, register_replica=False)\n",
    "                                        .add_pegasus_profiles(label=\"{0}_{1}_{2}\".format(sensor, ts, counter))\n",
    "                                    )\n",
    "                    \n",
    "\n",
    "                    # Increase counter\n",
    "                    counter += 1\n",
    "\n",
    "                    # Share files to jobs\n",
    "                    self.wf.add_jobs(convert2wav_job, convert2spectrogram_job, inference_job)\n",
    "                    self.wf.add_dependency(mkdir_job, children=[convert2wav_job, convert2spectrogram_job])\n",
    "\n",
    "                #merge predictions for sensor timestamps\n",
    "                merged_predictions = File(\"predictions_{0}_{1}.json\".format(sensor, ts))\n",
    "                predictions_sensor_files.append(merged_predictions)\n",
    "                merge_job_ts = (Job(\"merge\", _id=\"merge_{0}_{1}\".format(sensor, ts), node_label=\"merge_{0}_{1}\".format(sensor, ts))\n",
    "                                    .add_args(\"-i {0} -o {1}\".format(\" \".join([x.lfn for x in predictions_sensor_ts_files]), merged_predictions.lfn))\n",
    "                                    .add_inputs(*predictions_sensor_ts_files)\n",
    "                                    .add_outputs(merged_predictions, stage_out=True, register_replica=False)\n",
    "                                    .add_pegasus_profiles(label=\"{0}_{1}\".format(sensor, ts))\n",
    "                                )\n",
    "\n",
    "                self.wf.add_jobs(merge_job_ts)\n",
    "\n",
    "            #merge predictions for sensor if more than 1 files\n",
    "            if len(predictions_sensor_files) > 1:\n",
    "                merged_predictions = File(\"predictions_{0}.json\".format(sensor))\n",
    "                predictions_files.append(merged_predictions)\n",
    "                merge_job_sensor = (Job(\"merge\", _id=\"merge_{0}\".format(sensor, ts), node_label=\"merge_{0}\".format(sensor, ts))\n",
    "                                        .add_args(\"-i {0} -o {1}\".format(\" \".join([x.lfn for x in predictions_sensor_files]), merged_predictions.lfn))\n",
    "                                        .add_inputs(*predictions_sensor_files)\n",
    "                                        .add_outputs(merged_predictions, stage_out=True, register_replica=False)\n",
    "                                        .add_pegasus_profiles(label=\"{0}\".format(sensor))\n",
    "                                    )\n",
    "\n",
    "                self.wf.add_jobs(merge_job_sensor)\n",
    "\n",
    "        #merge predictions for all sensors if more than 1 files\n",
    "        if len(predictions_files) > 1:\n",
    "            merged_predictions = File(\"predictions_all.json\")\n",
    "            merge_job_all = (Job(\"merge\", _id=\"merge_all\".format(sensor, ts), node_label=\"merge_all\".format(sensor, ts))\n",
    "                                    .add_args(\"-i {0} -o {1}\".format(\" \".join([x.lfn for x in predictions_files]), merged_predictions.lfn))\n",
    "                                    .add_inputs(*predictions_files)\n",
    "                                    .add_outputs(merged_predictions, stage_out=True, register_replica=False)\n",
    "                            )\n",
    "\n",
    "            self.wf.add_jobs(merge_job_all)\n",
    "            \n",
    "\n",
    "#\n",
    "start_date = datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "if END_DATE:\n",
    "    end_date = datetime.strptime(END_DATE, '%Y-%m-%d')\n",
    "else:\n",
    "    end_date = start_date + timedelta(days=1)\n",
    "max_files = 200\n",
    "dagfile = 'workflow.yml'\n",
    "\n",
    "workflow = OrcasoundWorkflow(sensors=SENSORS, \n",
    "                             start_date=start_date, \n",
    "                             end_date=end_date, \n",
    "                             max_files=max_files, \n",
    "                             dagfile=dagfile)\n",
    "\n",
    "print(\"Creating execution sites...\")\n",
    "workflow.create_sites_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating workflow properties...\")\n",
    "workflow.create_pegasus_properties()\n",
    "\n",
    "print(\"Creating transformation catalog...\")\n",
    "workflow.create_transformation_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating replica catalog...\")\n",
    "workflow.create_replica_catalog()\n",
    "\n",
    "print(\"Creating orcasound workflow dag...\")\n",
    "workflow.create_workflow()\n",
    "\n",
    "workflow.write()\n",
    "print(\"Orcasound Workflow has been generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3adb46",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 2. Plan and Submit the Workflow\n",
    "\n",
    "We will now plan and submit the workflow for execution. By default we are running jobs on site **condorpool** i.e the selected ACCESS resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.plan_submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76c63a",
   "metadata": {},
   "source": [
    "After the workflow has been successfully planned and submitted, you can use the Python `Workflow` object in order to monitor the status of the workflow. It shows in detail the counts of jobs of each status and also the whether the job is idle or running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3380d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2af234",
   "metadata": {},
   "source": [
    "## 3.  Launch Pilots Jobs on ACCESS resources\n",
    "\n",
    "At this point you should have some idle jobs in the queue. They are idle because there are no resources yet to execute on. Resources can be brought in with the HTCondor Annex tool, by sending pilot jobs (also called glideins) to the ACCESS resource providers. These pilots have the following properties:\n",
    "\n",
    "A pilot can run multiple user jobs - it stays active until no more user jobs are available or until end of life has been reached, whichever comes first.\n",
    "\n",
    "A pilot is partitionable - job slots will dynamically be created based on the resource requirements in the user jobs. This means you can fit multiple user jobs on a compute node at the same time.\n",
    "\n",
    "A pilot will only run jobs for the user who started it.\n",
    "\n",
    "The process of starting pilots is described in the [ACCESS Pegasus Documentation](https://xsedetoaccess.ccs.uky.edu/confluence/redirect/ACCESS+Pegasus.html)\n",
    "\n",
    "## 4. Statistics\n",
    "\n",
    "Depending on if the workflow finished successfully or not, you have options on what to do next. If the workflow failed you can use `workflow.analyze()` do get help finding out what went wrong. If the workflow finished successfully, we can pull out some statistcs from the provenance database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe69043",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
