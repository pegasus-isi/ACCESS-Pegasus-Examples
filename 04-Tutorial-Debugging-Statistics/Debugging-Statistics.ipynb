{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Debugging\n",
    "\n",
    "When running complex computations (such as workflows) on complex computing infrastructure (for example HPC clusters), things will go wrong. It is therefore important to understand how to detect and debug issues as they appear. The good news is that Pegasus is doing a good job with the detection part, using for example exit codes, and provides tooling to help you debug. In this notebook, we will be using the same workflow as in the previous one, but introduce an error and see if we can detect it. \n",
    "\n",
    "To introduce the error, let's rename the input to something which will mismatch the workflow description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt.BADNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plan and run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from Pegasus.api import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class LLMRAGBooks:\n",
    "    \n",
    "    BASE_DIR = Path(\".\").resolve()\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.props = Properties()\n",
    "\n",
    "        self.wf = Workflow(\"llm-rag-books\")\n",
    "        self.tc = TransformationCatalog()\n",
    "        self.sc = SiteCatalog()\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        self.wf.add_transformation_catalog(self.tc)\n",
    "        self.wf.add_site_catalog(self.sc)\n",
    "        self.wf.add_replica_catalog(self.rc)\n",
    "        \n",
    "        self.wf_dir = str(Path(\".\").resolve())\n",
    "        self.shared_scratch_dir = os.path.join(self.wf_dir, \"scratch\")\n",
    "        self.local_storage_dir = os.path.join(self.wf_dir, \"output\")\n",
    "    \n",
    "    \n",
    "    # --- Write files in directory -------------------------------------------------\n",
    "    def write(self):\n",
    "        self.props.write()\n",
    "        self.sc.write()\n",
    "        self.rc.write()\n",
    "        self.tc.write()\n",
    "        \n",
    "        try:\n",
    "            self.wf.write()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    # --- Plan and Submit the workflow ----------------------------------------------\n",
    "    def plan_submit(self):\n",
    "        try:\n",
    "            self.wf.plan(submit=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Get status of the workflow -----------------------------------------------\n",
    "    def status(self):\n",
    "        try:\n",
    "            self.wf.status(long=True)\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "\n",
    "    # --- Start the workflow  -----------------------------------------------\n",
    "    def run(self):\n",
    "        try:\n",
    "            self.wf.run()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "    # --- Wait for the workflow to finish -----------------------------------------------\n",
    "    def wait(self):\n",
    "        try:\n",
    "            self.wf.wait()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "     \n",
    "    \n",
    "    # --- Analyze of a failed workflow -----------------------------------------------\n",
    "    def analyze(self):\n",
    "        try:\n",
    "            self.wf.analyze()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    # --- Get statistics of the workflow -----------------------------------------------\n",
    "    def statistics(self):\n",
    "        try:\n",
    "            self.wf.statistics()\n",
    "        except PegasusClientError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    # --- Configuration (Pegasus Properties) ---------------------------------------\n",
    "    def create_pegasus_properties(self):\n",
    "        \n",
    "        # Help Pegasus developers by sharing performance data (optional)\n",
    "        self.props[\"pegasus.monitord.encoding\"] = \"json\"\n",
    "        self.props[\"pegasus.catalog.workflow.amqp.url\"] = \"amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows\"\n",
    "\n",
    "        # nicer looking submit dirs\n",
    "        self.props[\"pegasus.dir.useTimestamp\"] = \"true\"\n",
    "        \n",
    "        # fail fast - save time when doing the tutorial\n",
    "        self.props[\"pegasus.mode\"] = \"tutorial\"\n",
    "\n",
    "        \n",
    "    # --- Site Catalog -------------------------------------------------------------\n",
    "    def create_sites_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.sc = SiteCatalog()\n",
    "\n",
    "        local = (Site(\"local\")\n",
    "                    .add_directories(\n",
    "                        Directory(Directory.SHARED_SCRATCH, self.shared_scratch_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.shared_scratch_dir, Operation.ALL)),\n",
    "                        Directory(Directory.LOCAL_STORAGE, self.local_storage_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + self.local_storage_dir, Operation.ALL))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        condorpool = (Site(exec_site_name)\n",
    "                        .add_condor_profile(universe=\"container\")\n",
    "                        .add_pegasus_profile(\n",
    "                            style=\"condor\"\n",
    "                        )\n",
    "                    )\n",
    "        condorpool.add_profiles(Namespace.ENV, LANG='C')\n",
    "        condorpool.add_profiles(Namespace.ENV, PYTHONUNBUFFERED='1')\n",
    "        \n",
    "        # exclude the ACCESS Pegasus TestPool \n",
    "        #condorpool.add_condor_profile(requirements=\"TestPool =!= True\")\n",
    "\n",
    "        # If you want to run on OSG, please specify your OSG ProjectName. For testing, feel\n",
    "        # free to use the USC_Deelman project (the PI of the Pegasus project).For\n",
    "        # production work, please use your own project.\n",
    "        #condorpool.add_profiles(Namespace.CONDOR, key=\"+ProjectName\", value=\"\\\"USC_Deelman\\\"\")\n",
    "        \n",
    "        self.sc.add_sites(local, condorpool)\n",
    "        \n",
    "\n",
    "    # --- Transformation Catalog (Executables and Containers) ----------------------\n",
    "    def create_transformation_catalog(self, exec_site_name=\"condorpool\"):\n",
    "        self.tc = TransformationCatalog()\n",
    "        \n",
    "        llm_rag_container = Container(\"llm_rag_container\",\n",
    "            container_type = Container.SINGULARITY,\n",
    "            image = \"http://download.pegasus.isi.edu/containers/llm-rag/llm-rag-v2.sif\",\n",
    "            image_site = \"web\"\n",
    "        )\n",
    "        \n",
    "        # main job wrapper\n",
    "        # note how gpus and other resources are requested\n",
    "        wrapper = Transformation(\"llm-wrapper\", \n",
    "                                 site=\"local\", \n",
    "                                 pfn=self.wf_dir+\"/bin/llm-wrapper.sh\", \n",
    "                                 is_stageable=True, \n",
    "                                 container=llm_rag_container)\\\n",
    "                  .add_pegasus_profiles(cores=1, gpus=1, memory=\"10 GB\", diskspace=\"15 GB\")\\\n",
    "                  .add_profiles(Namespace.CONDOR, key=\"require_gpus\", value=\"Capability >= 8.0\")\n",
    "\n",
    "        \n",
    "        self.tc.add_containers(llm_rag_container)\n",
    "        self.tc.add_transformations(wrapper)\n",
    "\n",
    "    \n",
    "    # --- Replica Catalog ----------------------------------------------------------\n",
    "    def create_replica_catalog(self):\n",
    "        self.rc = ReplicaCatalog()\n",
    "\n",
    "        # Add inference dependencies\n",
    "        self.rc.add_replica(\"local\", \"llm-rag.py\", \\\n",
    "                                     os.path.join(self.wf_dir, \"bin/llm-rag.py\"))\n",
    "        self.rc.add_replica(\"local\", \"Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt\", \\\n",
    "                                     os.path.join(self.wf_dir, \"inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt\"))\n",
    "     \n",
    "\n",
    "    # --- Create Workflow ----------------------------------------------------------\n",
    "    def create_workflow(self):\n",
    "        self.wf = Workflow(name=\"llm-rag-books\", infer_dependencies=True)\n",
    "        \n",
    "        # existing files - already listed in the replica catalog\n",
    "        llm_rag_py = File(\"llm-rag.py\")\n",
    "        book = File(\"Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt\")\n",
    "        \n",
    "        # these will be generated by the workflow\n",
    "        answers_txt = File(f\"{book}-answers.txt\")\n",
    "        ollama_log = File(f\"{book}-ollama.log\")\n",
    "        \n",
    "        job = (Job(\"llm-wrapper\")\n",
    "                  .add_args(book)\n",
    "                  .add_inputs(llm_rag_py)\n",
    "                  .add_inputs(book)\n",
    "                  .add_outputs(answers_txt, stage_out=True)\n",
    "                  .add_outputs(ollama_log, stage_out=True)\n",
    "              )\n",
    "        \n",
    "        self.wf.add_jobs(job)\n",
    "\n",
    "            \n",
    "workflow = LLMRAGBooks()\n",
    "\n",
    "print(\"Creating execution sites...\")\n",
    "workflow.create_sites_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating workflow properties...\")\n",
    "workflow.create_pegasus_properties()\n",
    "\n",
    "print(\"Creating transformation catalog...\")\n",
    "workflow.create_transformation_catalog(\"condorpool\")\n",
    "\n",
    "print(\"Creating replica catalog...\")\n",
    "workflow.create_replica_catalog()\n",
    "\n",
    "print(\"Creating workflow dag...\")\n",
    "workflow.create_workflow()\n",
    "\n",
    "workflow.write()\n",
    "print(\"Workflow has been generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.plan_submit()\n",
    "workflow.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the status bar and the state of the different jobs.\n",
    "\n",
    "## 3. Analyze\n",
    "\n",
    "When the workflow fails, we can use the Pegasus analyze tool to pinpoint the failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output we can see `ERROR:  Expected local file does not exist: /home/rynge/git/ACCESS-Pegasus-Examples/04-Tutorial-Debugging-Statistics/inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt'`, which means that the local file might not exist.\n",
    "\n",
    "## Resolving the issue\n",
    "\n",
    "The cause of the problem is a mismatch between the input file (`inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt.BADNAME`) and what we have specified in the workflow (`inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt`). The file in the input directory was misnamed to cause this issue for demonstration purposes.\n",
    "\n",
    "Let's resolve the issue by renaming the wrongly named input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mv inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt.BADNAME inputs/Alices_Adventures_in_Wonderland_by_Lewis_Carroll.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the workflow\n",
    "\n",
    "We can now restart the workflow from where it stopped. Alternatively to the `run()`, you could `plan_submit()` a new instance, but in that case the workflow would start all the way from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow.run()\n",
    "time.sleep(30)  # give the workflow some time to get started again\n",
    "workflow.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Pegasus collects provenance information during the workflow execution. By default, Pegasus launches all jobs through a process called `kickstart`, which captures runtime provenance data for each job. This data includes details about the execution environment, input and output files, execution parameters, and performance metrics. \n",
    "\n",
    "The collected provenance information is stored in a relational database, allowing users to analyze and summarize workflow executions. Pegasus provides tools such as `pegasus-statistics` to facilitate this analysis. To get a high level summary of the data, run `workflow.statistics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
