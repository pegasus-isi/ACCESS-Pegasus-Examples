{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegasus Tutorial For HTC Workflows on ACCESS Resources\n",
    "\n",
    "Welcome to the Pegasus tutorial notebook, which is intended for new users who want to get a quick overview of Pegasus concepts and usage. This tutorial covers:\n",
    "\n",
    " - Using the Pegasus API to generate an abstract workflow\n",
    " - Using the API to plan the abstract workflow into an executable workflow\n",
    " - Pegasus catalogs for sites, transformations, and data\n",
    " - Debug and recover from failures (02-Debugging notebook)\n",
    " - Command line tools (03-Command-Line-Tools notebook)\n",
    " \n",
    "For a quick overview of Pegasus, please see this short YouTube video:\n",
    "\n",
    "[![A 5 Minute Introduction](../images/youtube-pegasus-intro.png)](https://www.youtube.com/watch?v=MNN80OHMQUQ \"A 5 Minute Introduction\")\n",
    "\n",
    "## Allocation Optional for Tutorial Workflows\n",
    "\n",
    "Typically, using ACCESS Pegasus to run workflows necessitates users to link their own allocations. However, the initial notebooks in this guide are pre-configured to operate on a modest resource bundled with ACCESS Pegasus. As you progress to more complex sample workflows, such as Variant Calling, you'll be required to utilize your own allocation.\n",
    "\n",
    "If you prefer to run the workflow using your own allocation, you can provision as described in the documentation, and comment out the `+run_on_test_cluster` property below. Currently, the following resources are supported\n",
    "\n",
    "* Purdue Anvil\n",
    "* SDSC Expanse\n",
    "* PSC Bridges2\n",
    "* IU Jetstream2\n",
    "\n",
    "![Pegasus ACCESS Overview](../images/pegasus-access-overview.png)\n",
    "\n",
    "\n",
    "## Diamond Workflow\n",
    "\n",
    "This notebook will generate the **diamond workflow** illustrated below, then plan and execute the workflow on the local condorpool. Rectangles represent input/output files, and ovals represent compute jobs. The arrows represent file dependencies between each compute job. \n",
    "\n",
    "![Diamond Workflow](../images/diamond.svg)\n",
    "\n",
    "The abstract workflow description that you specify to Pegasus is portable, and usually does not contain any locations to physical input files, executables or cluster end points where jobs are executed. Pegasus uses three information catalogs during the planning process. A picture of this process is:\n",
    "\n",
    "![Catalogs](../images/catalogs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python API\n",
    "\n",
    "Pegasus 5.0 introduces a new Python API, which is fully documented in the [Pegasus reference guide](https://pegasus.isi.edu/documentation/reference-guide/api-reference.html). A high level overview of the components:\n",
    "<br>\n",
    "```\n",
    "from Pegasus.api.mixins import EventType, Namespace\n",
    "from Pegasus.api.properties import Properties\n",
    "from Pegasus.api.replica_catalog import File, ReplicaCatalog\n",
    "from Pegasus.api.site_catalog import (\n",
    "    OS,\n",
    "    Arch,\n",
    "    Directory,\n",
    "    FileServer,\n",
    "    Grid,\n",
    "    Operation,\n",
    "    Scheduler,\n",
    "    Site,\n",
    "    SiteCatalog,\n",
    ")\n",
    "from Pegasus.api.transformation_catalog import (\n",
    "    Container,\n",
    "    Transformation,\n",
    "    TransformationCatalog,\n",
    "    TransformationSite,\n",
    ")\n",
    "from Pegasus.api.workflow import Job, SubWorkflow, Workflow\n",
    "from Pegasus.client._client import PegasusClientError\n",
    "```\n",
    "\n",
    "While you can import just parts of the API, the most convenient way is to just import it all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pegasus.api import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Logging\n",
    "\n",
    "Configure logging. While this is **not required**, it is useful for seeing output from tools such as `pegasus-plan`, `pegasus-analyzer`, etc. when using these python wrappers. Here we also include a few other imports we might need further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "BASE_DIR = Path(\".\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pegasus Properties\n",
    "\n",
    "The `pegasus.properties` file can now be generated using the `Properties()` object as shown below. To see a list of the most commonly used properties, you can use `Properties.ls(prefix)`. By default, `pegasus-plan` will look in `cwd` for a `pegasus.properties` file if one is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Properties ---------------------------------------------------------------\n",
    "props = Properties()\n",
    "props[\"pegasus.monitord.encoding\"] = \"json\"                                                                    \n",
    "props[\"pegasus.catalog.workflow.amqp.url\"] = \"amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows\"\n",
    "props[\"pegasus.mode\"] = \"tutorial\" # speeds up tutorial workflows - remove for production ones\n",
    "\n",
    "# Allow the jobs to run on the test cluster. You do not need to provision\n",
    "# resources from your own allocations in this case, but the cluster is small\n",
    "# and should not be used for production workloads.\n",
    "props.add_site_profile(\"condorpool\", \"condor\", \"+run_on_test_cluster\", \"true\")\n",
    "\n",
    "props.write() # written to ./pegasus.properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties.ls(\"condor.request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Replica Catalog (Specify Initial Input Files)\n",
    "\n",
    "Any initial input files given to the workflow should be specified in the `ReplicaCatalog`. This object tells Pegasus where each input file is physically located. First, we create a file that will be used as input to this workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f.a\", \"w\") as f:\n",
    "    f.write(\"This is the contents of the input file for the diamond workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `./f.a` will be used in this workflow, and so we create a corresponding `File` object. Metadata may also be added to the file as shown below.\n",
    "\n",
    "Next, a `ReplicaCatalog` object is created so that the physical locations of each input file can be cataloged. This is done using the `ReplicaCatalog.add_replica(site, file, path)` function. As the file `f.a` resides here on the submit machine, we use the reserved keyword `local` for the site parameter. Second, the `File` object is passed in for the `file` parameter. Finally, the absolute path to the file is given. `pathlib.Path` may be used as long as an absolute path is given. \n",
    "\n",
    "By default, `pegasus-plan` will look in `cwd` for a `replicas.yml` file if one is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replicas -----------------------------------------------------------------\n",
    "fa = File(\"f.a\").add_metadata(creator=\"ryan\")\n",
    "rc = ReplicaCatalog()\\\n",
    "    .add_replica(\"local\", fa, Path(\".\").resolve() / \"f.a\")\\\n",
    "    .write() # written to ./replicas.yml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat replicas.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Transformation Catalog (Specify Executables Used)\n",
    "\n",
    "Any executable (referred to as ***transformations***) used by the workflow needs to be specified in the `TransformationCatalog`. This is done by creating `Transformation` objects, which represent executables. Once created, these must be added to the `TransformationCatalog` object. \n",
    "\n",
    "By default, `pegasus-plan` will look in `cwd` for a `transformations.yml` file.\n",
    "\n",
    "For ACCESS, we recommend users specify containers in which their jobs run in. This allows you to\n",
    "have similar environment in which jobs run irrespective of the ACCESS resource on which \n",
    "the job is launched.\n",
    "\n",
    "In Pegasus, users have the option of either using a different container for each executable or same container for all executables. When using containers with Pegasus you have two options\n",
    "\n",
    "1. The container has your executables pre installed. In that case in your transformation catalog, you specify the PFN as the path in the container where your executable is accessible\n",
    "\n",
    "2. The other case, is you are using a generic baseline container and want to let Pegasus stage your executables in at runtime. To do that you can mark the executable as **stageable** (is_stageable as True) and Pegasus will stage the executable into the container, as part of executable staging.\n",
    "\n",
    "In the example below, we are indicating that the preprocess, findrange and analyze executables need a container named *base_container* to run. However, we are going to let Pegasus stage them into container when your workflow runs from their location on site `condorpool` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Container ----------------------------------------------------------\n",
    "\n",
    "base_container = Container(\n",
    "                  \"base-container\",\n",
    "                  Container.SINGULARITY,\n",
    "                  image=\"docker://karanvahi/pegasus-tutorial-minimal\"\n",
    "    \n",
    "                  # comment out the location below (and comment the above location) \n",
    "                  # if you run into docker rate pull limits. Do this if your  \n",
    "                  # workflow fails on the first try with stage-in jobs fail \n",
    "                  # with error like ERROR: toomanyrequests: Too Many Requests. OR\n",
    "                  # You have reached your pull rate limit. You may increase \n",
    "                  # the limit by authenticating and upgrading: \n",
    "                  # ttps://www.docker.com/increase-rate-limits. \n",
    "                  # You must authenticate your pull requests.\n",
    "                  #\n",
    "                  # This is why Pegasus supports tar files of containers, \n",
    "                  # and also ensures the pull from a docker hub happens only \n",
    "                  # once per workflow\n",
    "    \n",
    "                  #image=\"http://download.pegasus.isi.edu/pegasus/tutorial/pegasus-tutorial-minimal.tar.gz\"\n",
    "               )\n",
    "\n",
    "\n",
    "# --- Transformations ----------------------------------------------------------\n",
    "preprocess = Transformation(\n",
    "                \"preprocess\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/usr/bin/pegasus-keg\",\n",
    "                is_stageable=True,\n",
    "                container=base_container,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            ).add_profiles(Namespace.CONDOR, request_disk=\"120MB\")\n",
    "\n",
    "findrange = Transformation(\n",
    "                \"findrange\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/usr/bin/pegasus-keg\",\n",
    "                is_stageable=True,\n",
    "                container=base_container,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            ).add_profiles(Namespace.CONDOR, request_disk=\"120MB\")\n",
    "\n",
    "analyze = Transformation(\n",
    "                \"analyze\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/usr/bin/pegasus-keg\",\n",
    "                is_stageable=True,\n",
    "                container=base_container,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            ).add_profiles(Namespace.CONDOR, request_disk=\"120MB\")\n",
    "\n",
    "tc = TransformationCatalog()\\\n",
    "    .add_containers(base_container)\\\n",
    "    .add_transformations(preprocess, findrange, analyze)\\\n",
    "    .write() # written to ./transformations.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat transformations.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the container is listed once, and multiple transformations can refer to the same container.\n",
    "\n",
    "Some attributes to keep an eye out for\n",
    "- *name*  the name assigned to the container that is used as a reference handle when describing executables in Transformation\n",
    "\n",
    "- *type*  type of Container. Usually is Dokcer or Singularity\n",
    "\n",
    "- *image* - URL to image in a docker|singularity hub or URL to an existing docker image exported as a tar file or singularity image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create a Site Catalog\n",
    "\n",
    "A Site Catalog allows you to describe to Pegasus what your sites look alike. By default, Pegasus always\n",
    "creates two default sites\n",
    "\n",
    "* local - it is used to indicate the workflow submit node from where you are issuing pegasus commands. **local** site is usually used to run only data management tasks that Pegasus adds to the workflow. The users compute jobs are not executed on this site.\n",
    "* condorpool - it is used to indicate the default execution site that consists of condor workers. For this tutorial, the **condorpool** site will be composed of condor workers launched by pilot jobs on ACCESS sites in Section 10.\n",
    "\n",
    "In this tutorial, we create a local site mainly to specify a job environment setup file, that gets sourced before a job runs on an ACCESS resources, and loads all the relevant modules for the job (namely singularity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sites -----------------------------------------------------------------\n",
    "# add a local site with an optional job env file to use for compute jobs\n",
    "shared_scratch_dir = \"{}/work\".format(BASE_DIR)\n",
    "local_storage_dir = \"{}/storage\".format(BASE_DIR)\n",
    "\n",
    "local = Site(\"local\") \\\n",
    "    .add_directories(\n",
    "    Directory(Directory.SHARED_SCRATCH, shared_scratch_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + shared_scratch_dir, Operation.ALL)),\n",
    "    Directory(Directory.LOCAL_STORAGE, local_storage_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + local_storage_dir, Operation.ALL)))\n",
    "\n",
    "job_env_file = Path(str(BASE_DIR) + \"/../tools/job-env-setup.sh\").resolve()\n",
    "local.add_pegasus_profile(pegasus_lite_env_source=job_env_file)\n",
    "\n",
    "sc = SiteCatalog()\\\n",
    "   .add_sites(local)\\\n",
    "   .write() # written to ./sites.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sites.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create the Workflow\n",
    "\n",
    "The `Workflow` object is used to store jobs and dependencies between each job. Typical job creation is as follows:\n",
    "\n",
    "```\n",
    "# Define job Input/Output files\n",
    "input_file = File(\"input.txt\")\n",
    "output_file1 = File(\"output1.txt\")\n",
    "output_file2 = File(\"output2.txt\")\n",
    "\n",
    "# Define job, passing in the transformation (executable) it will use\n",
    "j = Job(transformation_obj)\n",
    "\n",
    "# Specify command line arguments (if any) which will be passed to the transformation when run\n",
    "j.add_args(\"arg1\", \"arg2\", input_file, \"arg3\", output_file)\n",
    "\n",
    "# Specify input files (if any)\n",
    "j.add_inputs(input_file)\n",
    "\n",
    "# Specify output files (if any)\n",
    "j.add_outputs(output_file1, output_file2)\n",
    "\n",
    "# Add profiles to the job\n",
    "j.add_env(FOO=\"bar\")\n",
    "j.add_profiles(Namespace.PEGASUS, key=\"checkpoint.time\", value=1)\n",
    "\n",
    "# Add the job to the workflow object\n",
    "wf.add_jobs(j)\n",
    "```\n",
    "\n",
    "By default, depedencies between jobs are inferred based on input and output files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Workflow -----------------------------------------------------------------\n",
    "wf = Workflow(\"blackdiamond\")\n",
    "\n",
    "fb1 = File(\"f.b1\")\n",
    "fb2 = File(\"f.b2\")\n",
    "job_preprocess = Job(preprocess)\\\n",
    "                    .add_args(\"-a\", \"preprocess\", \"-T\", \"3\", \"-i\", fa, \"-o\", fb1, fb2)\\\n",
    "                    .add_inputs(fa)\\\n",
    "                    .add_outputs(fb1, fb2)\n",
    "\n",
    "fc1 = File(\"f.c1\")\n",
    "job_findrange_1 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb1, \"-o\", fc1)\\\n",
    "                    .add_inputs(fb1)\\\n",
    "                    .add_outputs(fc1)\n",
    "\n",
    "fc2 = File(\"f.c2\")\n",
    "job_findrange_2 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb2, \"-o\", fc2)\\\n",
    "                    .add_inputs(fb2)\\\n",
    "                    .add_outputs(fc2)\n",
    "\n",
    "fd = File(\"f.d\")\n",
    "job_analyze = Job(analyze)\\\n",
    "                .add_args(\"-a\", \"analyze\", \"-T\", \"3\", \"-i\", fc1, fc2, \"-o\", fd)\\\n",
    "                .add_inputs(fc1, fc2)\\\n",
    "                .add_outputs(fd)\n",
    "\n",
    "wf.add_jobs(job_preprocess, job_findrange_1, job_findrange_2, job_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizing the Workflow\n",
    "\n",
    "Once you have defined your abstract workflow, you can use `pegasus-graphviz` to visualize it. `Workflow.graph()` will invoke `pegasus-graphviz` internally and render your workflow using one of the available formats such as `png`. **Note that Workflow.write() must be invoked before calling Workflow.graph().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wf.write()\n",
    "    wf.graph(include_files=True, label=\"xform-id\", output=\"graph.png\")\n",
    "except PegasusClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rendered workflow\n",
    "from IPython.display import Image\n",
    "Image(filename='graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run the Workflow\n",
    "\n",
    "When working in Python, we can just use the reference do the `Workflow` object, you can plan, run, and monitor the workflow directly. These are wrappers around Pegasus CLI tools, and as such, the same arguments may be passed to them. \n",
    "\n",
    "**Note that the Pegasus binaries must be added to your PATH for this to work.**\n",
    "\n",
    "Please wait for the progress bar to indicate that the workflow has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    wf.plan(submit=True)\\\n",
    "        .wait()\n",
    "except PegasusClientError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line in the output that starts with pegasus-status, contains the command you can use to monitor the status of the workflow. We will cover this command line tool in the next couple of notbooks. The path it contains is the path to the submit directory where all of the files required to submit and monitor the workflow are stored. For now we will just continue to use the Python `Workflow` object.\n",
    "\n",
    "## 10.  Optional: Launch Pilots Jobs on ACCESS resources\n",
    "\n",
    "If you opted to use the included test cluster, the jobs should now start running. Please read the rest of this section to understand how provisioning works in the production case, but no other action is necessary. \n",
    "\n",
    "If you opted to run the example using your allocation, you should now have some idle jobs in the queue. They are idle because there are no resources yet to execute on. Resources can be brought in with the HTCondor Annex tool, by sending pilot jobs (also called glideins) to the ACCESS resource providers. These pilots have the following properties:\n",
    "\n",
    "A pilot can run multiple user jobs - it stays active until no more user jobs are available or until end of life has been reached, whichever comes first.\n",
    "\n",
    "A pilot is partitionable - job slots will dynamically be created based on the resource requirements in the user jobs. This means you can fit multiple user jobs on a compute node at the same time.\n",
    "\n",
    "A pilot will only run jobs for the user who started it.\n",
    "\n",
    "The process of starting pilots is described in the [ACCESS Pegasus Documentation](https://xsedetoaccess.ccs.uky.edu/confluence/redirect/ACCESS+Pegasus.html)\n",
    "\n",
    "\n",
    "## 11. Statistics\n",
    "\n",
    "Depending on if the workflow finished successfully or not, you have options on what to do next. If the workflow failed you can use `wf.analyze()` do get help finding out what went wrong. If the workflow finished successfully, we can pull out some statistcs from the provenance database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    wf.statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Container Setup on a Worker Node\n",
    "\n",
    "Now that we have been able to run the workflow succesfully, lets look beneath the covers to see how a job that has to run in a container gets setup on a worker node. The container setup for a job happens within PegasusLite, a light-weight Pegasus remote execution engine which wraps the user task on the remote worker node when a job is scheduled to the node. \n",
    "\n",
    "PegasusLite is responsible for figuring out the appropriate job directory in which the job executes, staging-in datasets that a job requires, launching the job, staging-out data, and cleaning up the job directory.\n",
    "\n",
    "![Container Setup in PegasusLite](../images/container-host.png)\n",
    "\n",
    "To see how Pegasus handled the container in this case, let’s look at some plumbing for one of the `analyze` job. The HTCondor submit file can be seen with:\n",
    "\n",
    "```bash\n",
    "$ cat `find scitech/pegasus/blackdiamond/run0001 -name analyze_ID0000004.sub`\n",
    "```\n",
    "\n",
    "Look  at the transfer_input_files attribute line, and specifically for the `base-container` file. It is transferred together with all the other inputs for the job.\n",
    "\n",
    "\n",
    "transfer_input_files = analyze,f.c2,f.c1,**base-container**,..\n",
    "\n",
    "Looking at the corresponding .sh file we can see how Pegasus executed the container by invoking `docker run` on a script written out at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. What's Next?\n",
    "\n",
    "To continue exploring Pegasus, and specifically learn how to debug failed workflows, please open the notebook in `02-Debugging/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
