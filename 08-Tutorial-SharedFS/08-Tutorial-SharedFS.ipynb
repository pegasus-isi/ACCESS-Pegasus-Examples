{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Workflow on a Single ACCESS Resource and using the Shared Filesystem \n",
    "\n",
    "**Objective:** Learn about how you can run a workflow on a single ACCESS Resource (Expanse used as an example) and use the shared filesystem on it. \n",
    "\n",
    "In the previous notebook, you learnt about how to do provisioning using the command `htcondor annex` against an ACCESS resource. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "If you don't have an allocation on Expanse, you can use the annex command against the HPC ACCESS resource you have an allocation for. \n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Annex Setup (Need to do only once)\n",
    "\n",
    "\n",
    "\n",
    "To launch the pilot jobs from ACCESS Pegasus submit host, use the htcondor annex create command. If this is your first time doing an `annex` against a resource, you need to some one time setup. \n",
    "Please refer to \n",
    "[ACCESS Pegasus Annex documentation](https://access-ci.atlassian.net/wiki/spaces/ACCESSdocumentation/pages/564887666/HTCondor+Annex) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run a workflow against the Annex\n",
    "\n",
    "We will now run the same workflow that we ran in `03-Tutorial-Software` notebook that runs each job in a container against the annex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Setup the Replica and Transformation Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pegasus.api import *\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# we specify directories for inputs, executables and outputs\n",
    "# - directory where the executables that the workflow uses are placed.\n",
    "# - directory where the outputs should be placed.\n",
    "\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "EXECUTABLES_DIR = Path(BASE_DIR / \"..\" /  \"executables\").resolve()\n",
    "OUTPUT_DIR = Path(BASE_DIR /  \"output\").resolve() \n",
    "\n",
    "# --- Replicas -----------------------------------------------------------------\n",
    "fin = File(\"f.in\").add_metadata(creator=\"vahi\")\n",
    "rc = ReplicaCatalog()\\\n",
    "    .add_replica(\"remote\", fin, \"http://download.pegasus.isi.edu/tutorial/inputs/f.in\")\\\n",
    "    .write() # written to ./replicas.yml \n",
    "\n",
    "tc = TransformationCatalog()\n",
    "        \n",
    "wf_container = Container(\"wf_container\",\n",
    "    container_type = Container.SINGULARITY,\n",
    "    image = \"http://download.pegasus.isi.edu/containers/hello-world/hello-world.sif\",\n",
    "    image_site = \"web\"\n",
    ")\n",
    "\n",
    "# For each type of job in the workflow specify a transformation\n",
    "# When you instantiate a Job() object, you specify a transformation name\n",
    "# which is a logical identifier for the executable you want to run\n",
    "# when the job is launched on a remote node. \n",
    "#\n",
    "# In this workflow, we have two transformations \"hello\" and \"world\",\n",
    "# with each mapping to the same executable that is installed in\n",
    "# the container. is_stageable parameter is set to False to indicate\n",
    "# the executable is installed in the container.\n",
    "# Note: how cpu and other resources are requested\n",
    "hello = Transformation(\"hello\", \n",
    "                         site=\"web\", \n",
    "                         pfn=\"/opt/pegasus-tutorial/pegasus-keg.py\", \n",
    "                         is_stageable=False, \n",
    "                         container=wf_container)\\\n",
    "          .add_pegasus_profiles(cores=1, memory=\"1 GB\", diskspace=\"1 GB\")\n",
    "\n",
    "world = Transformation(\"world\", \n",
    "                         site=\"web\", \n",
    "                         pfn=\"/opt/pegasus-tutorial/pegasus-keg.py\", \n",
    "                         is_stageable=False, \n",
    "                         container=wf_container)\\\n",
    "          .add_pegasus_profiles(cores=1, memory=\"1 GB\", diskspace=\"1 GB\")\n",
    "\n",
    "tc.add_containers(wf_container)\n",
    "tc.add_transformations(hello, world)\n",
    "tc.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define a site for the Annex\n",
    "\n",
    "First update the variable EXPANSE_USERNAME to match your username on EXPANSE.\n",
    "If, you are doing an annex against a resource other than EXPANSE, you need to update the full path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the variables below should be updated to refer to your\n",
    "# username on expanse. There are of the form uxXXXXX\n",
    "cluster_shared_dir = \"/expanse/lustre/scratch/uxXXXXX/temp_project\"\n",
    "cluster_home_dir = \"/home/uxXXXXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now describe the expanse site in the Site Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SiteCatalog()   \n",
    "\n",
    "# add a profile to indicate an env script that should be sourced\n",
    "# before a job is run. In this case, it just loads singlaritypro\n",
    "# before a job is executed on Expanse.\n",
    "local_scratch_dir = os.path.join(BASE_DIR, \"scratch\")\n",
    "local_storage_dir = os.path.join(BASE_DIR, \"output\")\n",
    "      \n",
    "local = (Site(\"local\")\n",
    "             .add_directories(\n",
    "                        Directory(Directory.SHARED_SCRATCH, local_scratch_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + local_scratch_dir, Operation.ALL)),\n",
    "                        Directory(Directory.LOCAL_STORAGE, local_storage_dir)\n",
    "                            .add_file_servers(FileServer(\"file://\" + local_storage_dir, Operation.ALL))\n",
    "                    )\n",
    "            .add_pegasus_profile(\n",
    "                pegasus_lite_env_source=str(Path(BASE_DIR /  \"hpc_env_setup.sh\").resolve())\n",
    "            )\n",
    ")\n",
    "\n",
    "# define the site layout for the expanse resource\n",
    "EXEC_SITE=\"expanse\"\n",
    "expanse = (Site(EXEC_SITE)\n",
    "                .add_pegasus_profile(\n",
    "                    style=\"condor\",\n",
    "                    data_configuration=\"nonsharedfs\",\n",
    "                )\n",
    ")\n",
    "\n",
    "\n",
    "exec_site_shared_scratch_dir = os.path.join(cluster_shared_dir, \"pegasuswfs/scratch\")\n",
    "exec_site_shared_storage_dir = os.path.join(cluster_home_dir, \"pegasuswfs/outputs\")\n",
    "\n",
    "expanse.add_directories(\n",
    "    Directory(Directory.SHARED_SCRATCH, exec_site_shared_scratch_dir)\n",
    "    .add_file_servers(FileServer(\"file://\" + exec_site_shared_scratch_dir, Operation.ALL)),\n",
    "    Directory(Directory.LOCAL_STORAGE, exec_site_shared_storage_dir)\n",
    "    .add_file_servers(FileServer(\"file://\" + exec_site_shared_storage_dir, Operation.ALL))\n",
    ")\n",
    "expanse.add_profiles(Namespace.ENV, LANG='C')\n",
    "expanse.add_profiles(Namespace.ENV, PYTHONUNBUFFERED='1')\n",
    "\n",
    "# exclude the ACCESS Pegasus TestPool\n",
    "# we want it to run on our annex\n",
    "expanse.add_condor_profile(requirements=\"TestPool =!= True\")\n",
    "\n",
    "sc.add_sites(expanse, local)\n",
    "sc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sites.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define and Execute the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Workflow -----------------------------------------------------------------\n",
    "wf = Workflow(\"hello-world\")\n",
    "\n",
    "\n",
    "finter = File(\"f.inter\")\n",
    "fout = File(\"f.out\")\n",
    "\n",
    "job_hello = Job(\"hello\")\\\n",
    "                    .add_args(\"-T\", \"3\", \"-i\", fin, \"-o {}\".format(finter))\\\n",
    "                    .add_inputs(fin)\\\n",
    "                    .add_outputs(finter, stage_out=False)\n",
    "\n",
    "job_world = Job(\"world\")\\\n",
    "                    .add_args(\"-T\", \"3\", \"-i\", finter, \"-o {}\".format(fout))\\\n",
    "                    .add_inputs(finter)\\\n",
    "                    .add_outputs(fout)\n",
    "\n",
    "wf.add_jobs(job_hello, job_world)    \n",
    "\n",
    "# --- Run the Workflow ---------------------------------------------------\n",
    "# we plan the workflow to run on site expanse, and have the outputs placed\n",
    "# on the expanse site.\n",
    "try:\n",
    "    wf.write()\n",
    "    wf.plan(sites=[EXEC_SITE], output_sites=[EXEC_SITE], submit=True)\\\n",
    "      .status()      \n",
    "except PegasusClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up Annex against a HPC ACCESS Resource\n",
    "\n",
    "To launch the pilot jobs from ACCESS Pegasus submit host, use the htcondor annex create command.\n",
    "\n",
    "A sample invocation against SDSC Expanse is listed below.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "Note: you need to do it on the command line in a terminal.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "htcondor annex create --project <project-id> --lifetime 3600   --nodes 1  $USER QUEUE@RESOURCE\n",
    "```\n",
    "\n",
    "\n",
    "Please note the annex created should be named $USER as the ACCESS Pegasus HTCondor configuration automatically adds the annex name (same as use ACCESS Pegasus username) to the jobs as a job transform. You need to specify your project-id instead of <project-id>. And also update QUEUE and RESOURCE keywords to reflect the ACCESS resource against which you are doing the annex.\n",
    "\n",
    "Below is an invocation for doing an annex against queue named `compute` on SDSC resource `expanse` which requests 1 node (128 cores) for 60 minutes.\n",
    "\n",
    "```\n",
    "htcondor annex create --project <project-id> --lifetime 3600   --nodes 1  $USER compute@expanse\n",
    "```\n",
    "\n",
    "Please open a terminal and type the above command. Remember to update the project-id to match your project id. \n",
    "\n",
    "Sample invocation against EXPANSE is shown below.\n",
    "\n",
    "```\n",
    "htcondor annex add --project XXXX --lifetime 3600   --nodes 1  $USER compute@expanse\n",
    "This will (as the project 'XXX') request 1 nodes for 1.00 hours for an annex named 'vahi' from the queue named 'compute' on the system named \n",
    "'Expanse'.  To change the project, use --project.  To change the resources requested, use either --nodes or one or more of --cpus and --mem_mb. \n",
    " To change how long the resources are reqested for, use --lifetime (in seconds).\n",
    "This command will access the system named 'Expanse' via SSH.  To proceed, follow the prompts from that system below; to cancel, hit CTRL-C.\n",
    "Enter passphrase for key '/home/vahi/.ssh/annex': \n",
    "TOTP code for ux454545: 453580\n",
    "Thank you.\n",
    "Populating annex temporary directory... done.\n",
    "Requesting annex named 'vahi' from queue 'compute' on the system named 'Expanse'...\n",
    "    Step 8 of 8: Submitting SLURM job............    \n",
    "... requested.\n",
    "It may take some time for the system named 'Expanse' to establish the requested annex.\n",
    "To check on the status of the annex, run 'htcondor annex status vahi'.\n",
    "\n",
    "```\n",
    "    \n",
    "    \n",
    "## 4. Wait for the workflow to finish\n",
    "    \n",
    "We will now wait for the workflow to finish using the `wait()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Wait for the workflow to finish ---------------------------------------------------\n",
    "# we plan the workflow to run on site expanse, and have the outputs placed\n",
    "# on the expanse site.\n",
    "try:\n",
    "    wf.wait()     \n",
    "except PegasusClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspecting the generated output of the workflow\n",
    "\n",
    "In this case, the workflow places the outputs in a directory on expanse\n",
    "\n",
    "```\n",
    "[expanse ~]$ cat ~/pegasuswfs/outputs/f.out \n",
    "===================== contents start f.out =====================\n",
    "Hostname: exp-5-56 IP Addr: 198.202.102.215\n",
    "        --- start f.inter ----\n",
    "        ===================== contents start f.inter =====================\n",
    "        Hostname: exp-5-56 IP Addr: 198.202.102.215\n",
    "                --- start f.in ----\n",
    "                This is the contents of the input file hosted remotely for the hello world workflow!\n",
    "                --- end f.in ----\n",
    "        ===================== contents end   f.inter =====================\n",
    "        --- end f.inter ----\n",
    "===================== contents end   f.out =====================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
